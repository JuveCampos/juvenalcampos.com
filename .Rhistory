DT::datatable(options = list(
language = list(url = '//cdn.datatables.net/plug-ins/1.10.11/i18n/Spanish.json'),
pageLength = 5))
# Checamos la base
pop %>%
DT::datatable(options = list(
language = list(url = '//cdn.datatables.net/plug-ins/1.10.11/i18n/Spanish.json'),
pageLength = 5))
# Librerias
library(tidyverse)
library(tidyr)
# Procesamos datos
pop <- bd %>%
# Filtramos los renglones vacios,
# los renglones donde el Tamaño de localidad` es el Total y
# los `Grupos quinquenales de edad` son todos "Total"
filter(!is.na(Estimador) &
Estimador == "Valor" &
`Tamaño de localidad` == "Total" &
`Grupos quinquenales de edad` != "Total") %>%
# Hacemos pivot longer rotando las columnas hombres y mujeres
pivot_longer(cols = c("Hombres", "Mujeres"),
names_to = "Sexo",
values_to = "Poblacion por Sexo") %>%
# Nos quedamos con columnas utiles
select(`Entidad federativa`, `Grupos quinquenales de edad`,
`Población total`, Sexo, `Poblacion por Sexo`)
# Descarga de los datos.
library(curl)
library(readxl)
curl::curl_download(url = "https://www.inegi.org.mx/contenidos/programas/intercensal/2015/tabulados/01_poblacion_mor.xls", destfile = "mor_pop.xls")
# Leemos datos
# Por tamaño de localidad
bd <- read_xls("mor_pop.xls", sheet = 2, skip = 6)
# Librerias
library(tidyverse)
library(tidyr)
# Procesamos datos
pop <- bd %>%
# Filtramos los renglones vacios,
# los renglones donde el Tamaño de localidad` es el Total y
# los `Grupos quinquenales de edad` son todos "Total"
filter(!is.na(Estimador) &
Estimador == "Valor" &
`Tamaño de localidad` == "Total" &
`Grupos quinquenales de edad` != "Total") %>%
# Hacemos pivot longer rotando las columnas hombres y mujeres
pivot_longer(cols = c("Hombres", "Mujeres"),
names_to = "Sexo",
values_to = "Poblacion por Sexo") %>%
# Nos quedamos con columnas utiles
select(`Entidad federativa`, `Grupos quinquenales de edad`,
`Población total`, Sexo, `Poblacion por Sexo`)
# Checamos la base
pop
# Checamos la base
pop %>%
DT::datatable(options = list(
language = list(url = '//cdn.datatables.net/plug-ins/1.10.11/i18n/Spanish.json'),
pageLength = 5))
options(scipen = 999)
# Descarga de los datos.
library(curl)
library(readxl)
curl::curl_download(url = "https://www.inegi.org.mx/contenidos/programas/intercensal/2015/tabulados/01_poblacion_mor.xls",
destfile = "mor_pop.xls")
# Leemos datos
# Por tamaño de localidad
bd <- read_xls("mor_pop.xls", sheet = 2, skip = 6)
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(fig.width=100%)
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(fig.width="100%")
?opts_chunk$set
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(fig.width=12, fig.height=8)
### Grafica ----
ggplot(pop, aes(x = `Grupos quinquenales de edad`,
y = `Poblacion por Sexo`,
fill = Sexo)) +
geom_col(data = subset(pop, Sexo == "Hombres") %>%
mutate(`Poblacion por Sexo` = -`Poblacion por Sexo`),
width = 0.5, fill = "blue") +
geom_col(data = subset(pop, Sexo == "Mujeres"),
width = 0.5, fill = "pink") +
coord_flip()
# 2. Hechar a andar la pagina
blogdown::serve_site()
# 2. Hechar a andar la pagina
blogdown::serve_site()
blogdown:::insert_image_addin()
blogdown:::insert_image_addin()
blogdown:::insert_image_addin()
bd <- sf::st_read("/Users/admin/Downloads/AGUASCALIENTES.rds")
bd <- readRDS("/Users/admin/Downloads/AGUASCALIENTES.rds")
head(bd)
View(bd)
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(fig.width=9, fig.height=5)
# Descarga de los datos.
library(curl)
library(readxl)
library(tidyverse)
curl::curl_download(url = "https://www.inegi.org.mx/contenidos/programas/intercensal/2015/tabulados/01_poblacion_mor.xls", destfile = "Poblacion/mor_pop.xls")
# Descarga de los datos.
library(curl)
library(readxl)
library(tidyverse)
curl::curl_download(url = "https://www.inegi.org.mx/contenidos/programas/intercensal/2015/tabulados/01_poblacion_mor.xls", destfile = "mor_pop.xls")
# Leemos datos
# Por tamaño de localidad
mor <- read_xls("Poblacion/mor_pop.xls", sheet = 2, skip = 6)
# Descarga de los datos.
library(curl)
library(readxl)
library(tidyverse)
curl::curl_download(url = "https://www.inegi.org.mx/contenidos/programas/intercensal/2015/tabulados/01_poblacion_mor.xls", destfile = "mor_pop.xls")
# Leemos datos
# Por tamaño de localidad
mor <- read_xls("mor_pop.xls", sheet = 2, skip = 6)
# Procesado de los datos
pop <- mor %>%
# Filtramos los renglones vacios,
# los renglones donde el Tamaño de localidad` es el Total y
# los `Grupos quinquenales de edad` son todos "Total"
filter(!is.na(Estimador) &
Estimador == "Valor" &
`Tamaño de localidad` == "Total" &
`Grupos quinquenales de edad` != "Total") %>%
mutate(totH = sum(Hombres),
totM = sum(Mujeres)) %>%
mutate(Hombres = (Hombres/totH)*100,
Mujeres = (Mujeres/totM)*100
) %>%
select(-totH, -totM) %>%
# Hacemos pivot longer rotando las columnas hombres y mujeres
pivot_longer(cols = c("Hombres", "Mujeres"),
names_to = "Sexo",
values_to = "Poblacion por Sexo") %>%
# Nos quedamos con columnas utiles
select(`Entidad federativa`, `Grupos quinquenales de edad`,
`Población total`, Sexo, `Poblacion por Sexo`) %>%
filter(!(`Grupos quinquenales de edad` %in% c("75 años y más","No especificado")))
# Elaboracion de la grafica
ggplot(pop, aes(x = `Grupos quinquenales de edad`,
y = `Poblacion por Sexo`,
fill = Sexo)) +
geom_bar(data = subset(pop, Sexo == "Hombres") %>% mutate(`Poblacion por Sexo` = -`Poblacion por Sexo`),
stat = "identity", width = 0.5, fill = "blue") +
geom_bar(data = subset(pop, Sexo == "Mujeres"),
stat = "identity", width = 0.5, fill = "pink") +
coord_flip() +
ggthemes::theme_tufte() +
theme(plot.title = element_text(family = "Arial", hjust = 0.5, size = 20),
axis.text.x = element_text(family = "Arial"),
axis.text.y = element_text(family = "Arial")
) +
labs(title = "Pirámide Poblacional de Morelos, 2015",
x = "",
y = "Hombres                        Mujeres",
caption = "Fuente: INEGI. Encuesta intercensal 2015. Tabulados de Población \nSe omiten personas de 75 años y más, por venir aglomeradas en un mismo grupo de edad.") +
scale_y_continuous(breaks = seq(-12, 12, by = 2), labels = paste0(seq(-12, 12, by = 2), "%"))
# ggsave(filename= "Poblacion/ppMorelos.png", dpi = 300)
blogdown:::insert_image_addin()
# 2. Hechar a andar la pagina
blogdown::serve_site()
seq(-12, 12, by = 2)
c(seq(-12, 0, by = 2)*-1, seq(2, 12, by = 2))
# Descarga de los datos.
library(curl)
library(readxl)
library(tidyverse)
curl::curl_download(url = "https://www.inegi.org.mx/contenidos/programas/intercensal/2015/tabulados/01_poblacion_mor.xls", destfile = "mor_pop.xls")
# Leemos datos
# Por tamaño de localidad
mor <- read_xls("mor_pop.xls", sheet = 2, skip = 6)
# Procesado de los datos
pop <- mor %>%
# Filtramos los renglones vacios,
# los renglones donde el Tamaño de localidad` es el Total y
# los `Grupos quinquenales de edad` son todos "Total"
filter(!is.na(Estimador) &
Estimador == "Valor" &
`Tamaño de localidad` == "Total" &
`Grupos quinquenales de edad` != "Total") %>%
mutate(totH = sum(Hombres),
totM = sum(Mujeres)) %>%
mutate(Hombres = (Hombres/totH)*100,
Mujeres = (Mujeres/totM)*100
) %>%
select(-totH, -totM) %>%
# Hacemos pivot longer rotando las columnas hombres y mujeres
pivot_longer(cols = c("Hombres", "Mujeres"),
names_to = "Sexo",
values_to = "Poblacion por Sexo") %>%
# Nos quedamos con columnas utiles
select(`Entidad federativa`, `Grupos quinquenales de edad`,
`Población total`, Sexo, `Poblacion por Sexo`) %>%
filter(!(`Grupos quinquenales de edad` %in% c("75 años y más","No especificado")))
# Elaboracion de la grafica
ggplot(pop, aes(x = `Grupos quinquenales de edad`,
y = `Poblacion por Sexo`,
fill = Sexo)) +
geom_bar(data = subset(pop, Sexo == "Hombres") %>% mutate(`Poblacion por Sexo` = -`Poblacion por Sexo`),
stat = "identity", width = 0.5, fill = "blue") +
geom_bar(data = subset(pop, Sexo == "Mujeres"),
stat = "identity", width = 0.5, fill = "pink") +
coord_flip() +
ggthemes::theme_tufte() +
theme(plot.title = element_text(family = "Arial", hjust = 0.5, size = 20),
axis.text.x = element_text(family = "Arial"),
axis.text.y = element_text(family = "Arial")
) +
labs(title = "Pirámide Poblacional de Morelos, 2015",
x = "",
y = "Hombres                        Mujeres",
caption = "Fuente: INEGI. Encuesta intercensal 2015. Tabulados de Población \nSe omiten personas de 75 años y más, por venir aglomeradas en un mismo grupo de edad.") +
scale_y_continuous(breaks = seq(-12, 12, by = 2), labels = paste0(c(seq(-12, 0, by = 2)*-1, seq(2, 12, by = 2)), "%"))
ggsave(filename= "Poblacion/ppMorelos.png", dpi = 300)
blogdown:::insert_image_addin()
blogdown:::insert_image_addin()
# 2. Hechar a andar la pagina
blogdown::serve_site()
# 2. Hechar a andar la pagina
blogdown::serve_site()
# 2. Hechar a andar la pagina
blogdown::serve_site()
blogdown:::new_post_addin()
# 2. Hechar a andar la pagina
blogdown::serve_site()
blogdown:::insert_image_addin()
knitr::opts_chunk$set(echo = TRUE)
# Librerias
library(sf)
library(tidyverse)
# Apertura del archivo (solo abrimos el archivo *.shp)
f <- st_read("static/BDs/shape Frontera/Mexico_and_US_Border.shp")
# Apertura del archivo (solo abrimos el archivo *.shp)
getwd()
f <- st_read("/../static/BDs/shape Frontera/Mexico_and_US_Border.shp")
f <- st_read("../../static/BDs/shape Frontera/Mexico_and_US_Border.shp")
f <- st_read("../../static/BDs/shape Frontera/Mexico_and_US_Border.shp", quiet = TRUE)
# Ploteado (te recomiendo que no le muevas al max.plot = 1)
plot(f, max.plot = 1)
# Las coordenadas del Colmex en formato tabla-dataframe
pto <- data.frame(x = -99.20775, y = 19.303741) %>%
st_as_sf(coords = c("x", "y"))
# Homologamos el Sistema de Coordenadas de Referencia con la base de la línea de la Frontera Norte
st_crs(pto) <- st_crs(f)
st_distance(pto, f)
# Descomponemos la linea en sus coordenadas
ptos_linea <- st_coordinates(f) %>%
as.data.frame() %>%
st_as_sf(coords = c("X", "Y"))
st_crs(ptos_linea) <- st_crs(f)
class(ptos_linea)
st_crs(ptos_linea)
distancias <- st_distance(ptos_linea, pto)
head(distancias)
# Obtencion de la distancia minima
distancia_minima <- min(distancias)
# En kilometros
(distancia_minima / 1000) %>% as.numeric()
# Punto minimo
punto_frontera <-
ptos_linea[distancias == distancia_minima,]
# linea de distancia
linea <- st_linestring(matrix(c(pto[,"geometry"] %>%
st_coordinates(),
punto_frontera[,"geometry"] %>% st_coordinates()), ncol = 2, byrow = TRUE))
blogdown:::insert_image_addin()
# 2. Hechar a andar la pagina
blogdown::serve_site()
blogdown:::insert_image_addin()
# 2. Hechar a andar la pagina
blogdown::serve_site()
blogdown:::insert_image_addin()
blogdown:::insert_image_addin()
# 2. Hechar a andar la pagina
blogdown::serve_site()
blogdown:::insert_image_addin()
# 2. Hechar a andar la pagina
blogdown::serve_site()
knitr::opts_chunk$set(echo = TRUE)
st_crs(f)
?st_distance
?sf::st_distance
sf::st_distance
# Librerias
library(sf)
library(tidyverse)
# Apertura del archivo (solo abrimos el archivo *.shp)
f <- st_read("Mexico_and_US_Border.shp")
# Las coordenadas del Colmex en formato tabla-dataframe
pto <- data.frame(x = -99.20775, y = 19.303741) %>%
st_as_sf(coords = c("x", "y"))
# Homologamos el Sistema de Coordenadas de Referencia con la base de la línea de la Frontera Norte
st_crs(pto) <- st_crs(f)
# Librerias
library(sf)
library(tidyverse)
# Apertura del archivo (solo abrimos el archivo *.shp)
f <- st_read("../../static/BDs/shape Frontera/Mexico_and_US_Border.shp", quiet = TRUE)
# Las coordenadas del Colmex en formato tabla-dataframe
pto <- data.frame(x = -99.20775, y = 19.303741) %>%
st_as_sf(coords = c("x", "y"))
# Homologamos el Sistema de Coordenadas de Referencia con la base de la línea de la Frontera Norte
st_crs(pto) <- st_crs(f)
# Descomponemos la linea en sus coordenadas
ptos_linea <- st_coordinates(f) %>%
as.data.frame() %>%
st_as_sf(coords = c("X", "Y"))
st_crs(ptos_linea) <- st_crs(f)
class(ptos_linea)
st_crs(ptos_linea)
# Calculo de las distancias
distancias <- st_distance(ptos_linea, pto)
# Observamos los primeros registros
head(distancias)
# Obtencion de la distancia minima
distancia_minima <- min(distancias)
# En kilometros
(distancia_minima / 1000) %>% as.numeric()
# Punto minimo
punto_frontera <-
ptos_linea[distancias == distancia_minima,]
# Linea de distancia mínima
linea <- st_linestring(matrix(c(pto[,"geometry"] %>%
st_coordinates(),
punto_frontera[,"geometry"] %>% st_coordinates()), ncol = 2, byrow = TRUE))
library(leaflet)
# Hacemos el mapa
leaflet() %>%
addTiles() %>%
addCircleMarkers(data = pto) %>%
addCircleMarkers(data = punto_frontera) %>%
addPolylines(data = linea) %>%
addPolylines(data = f, color = "red")
# 2. Hechar a andar la pagina
blogdown::serve_site()
# 2. Hechar a andar la pagina
blogdown::serve_site()
# 2. Hechar a andar la pagina
blogdown::serve_site()
# 2. Hechar a andar la pagina
blogdown::serve_site()
# Librerias
library(sf)
library(tidyverse)
# Apertura del archivo (solo abrimos el archivo *.shp)
f <- st_read("../../static/BDs/shape Frontera/Mexico_and_US_Border.shp", quiet = TRUE)
# Ploteado (te recomiendo que no le muevas al max.plot = 1)
plot(f, max.plot = 1)
# Las coordenadas del Colmex en formato tabla-dataframe
pto <- data.frame(x = -99.20775, y = 19.303741) %>%
st_as_sf(coords = c("x", "y"))
# Homologamos el Sistema de Coordenadas de Referencia con la base de la línea de la Frontera Norte
st_crs(pto) <- st_crs(f)
st_distance(pto, f)
# Descomponemos la linea en sus coordenadas
ptos_linea <- st_coordinates(f) %>%
as.data.frame() %>%
st_as_sf(coords = c("X", "Y"))
st_crs(ptos_linea) <- st_crs(f)
class(ptos_linea)
st_crs(ptos_linea)
# Calculo de las distancias
distancias <- st_distance(ptos_linea, pto)
# Observamos los primeros registros
head(distancias)
# Obtencion de la distancia minima
distancia_minima <- min(distancias)
# En kilometros
(distancia_minima / 1000) %>% as.numeric()
# Punto minimo
punto_frontera <-
ptos_linea[distancias == distancia_minima,]
# Linea de distancia mínima
linea <- st_linestring(matrix(c(pto[,"geometry"] %>%
st_coordinates(),
punto_frontera[,"geometry"] %>% st_coordinates()), ncol = 2, byrow = TRUE))
library(leaflet)
# Hacemos el mapa
leaflet() %>%
addTiles() %>%
addCircleMarkers(data = pto) %>%
addCircleMarkers(data = punto_frontera) %>%
addPolylines(data = linea) %>%
addPolylines(data = f, color = "red")
# Función para calcular las distancias.
distancia <- function(X, Y){
pto <- data.frame(x = X, y = Y) %>%
st_as_sf(coords = c("x", "y"))
st_crs(pto) <- st_crs(f)
st_distance(pto, f)
}
# Distancia a un punto del mpio de Mexicali, BC
distancia(X = -115.418556, Y = 31.795112)
# Distancia a Puerto Peñasco, Sonora
distancia(X = -113.534104, Y = 31.309766)
# Distancia al CIDE
distancia(X = -99.263426, Y = 19.374515)
# Distancias a todos estos puntos
distancia(X = c(-115.418556,-113.534104, -99.263426),
Y = c(31.795112, 31.309766, 19.374515))
# Funcion para dibujar las lineas de minima distancia
# Nota, esta función da por hecho que previamente ya cargamos
# la base de datos de la frontera y la almacenamos en el objeto f
dibuja_lineas_minima_distancia <- function(X,Y){
# Creamos el punto a partir de los argumentos X y Y
pto <- data.frame(x = X, y = Y) %>%
st_as_sf(coords = c("x", "y"))
# Homologamos el Sistema de Coordenadas de Referencia
st_crs(pto) <- st_crs(f)
# Extraemos los vértices de la linea
ptos_linea <- st_coordinates(f) %>%
as.data.frame() %>%
st_as_sf(coords = c("X", "Y"))
# Homologamos el Sistema de Coordenadas de Referencia
st_crs(ptos_linea) <- st_crs(f)
# Sacamos las distancias del punto a todos los vertices de la frontera
distancias <- st_distance(ptos_linea, pto)
# Obtencion de la distancia minima
distancia_minima <- min(distancias)
# Guardamos el punto de la frontera con la distancia minima
punto_frontera <<-
ptos_linea[distancias == distancia_minima,]
# Construimos la linea de distancia minima
linea <- st_linestring(matrix(c(pto[,"geometry"] %>%
st_coordinates(),
punto_frontera[,"geometry"] %>%       st_coordinates()), ncol = 2, byrow = TRUE))
# Seleccionamos la linea como objeto a retornar de la funcion
return(linea)
}
# Probamos la funcion, sacando la linea del CIDE a la frontera
lineaCIDE <- dibuja_lineas_minima_distancia(X = -99.263426, Y = 19.374515)
# Dibujamos el mapa
leaflet(lineaCIDE) %>%
addTiles() %>%
addPolylines(color = "#005700")
# 2. Hechar a andar la pagina
blogdown::serve_site()
# 2. Hechar a andar la pagina
blogdown::serve_site()
blogdown:::new_post_addin()
blogdown:::insert_image_addin()
blogdown:::insert_image_addin()
blogdown:::insert_image_addin()
blogdown:::insert_image_addin()
blogdown:::insert_image_addin()
blogdown:::insert_image_addin()
blogdown:::insert_image_addin()
blogdown:::insert_image_addin()
blogdown:::insert_image_addin()
# 2. Hechar a andar la pagina
blogdown::serve_site()
blogdown:::new_post_addin()
# Librerías ----
library(tidyverse)
library(sf)
library(leaflet)
# Datos ----
url_shape <- "https://github.com/JuveCampos/colaboracionesConAmi/raw/master/01_Datos/Shapes/mpios.geojson"
# Leemos el shape
bd <- st_read(url_shape,
quiet = T)
# Datos ----
url_shape <- "https://raw.githubusercontent.com/JuveCampos/juveBlog/master/cortando%20Islas/mpios.geojson"
# Leemos el shape
bd <- st_read(url_shape,
quiet = T)
# Filtramos Colima
colima <- bd %>% filter(NOM_ENT == "Colima")
blogdown:::insert_image_addin()
blogdown:::insert_image_addin()
# 2. Hechar a andar la pagina
blogdown::serve_site()
blogdown:::insert_image_addin()
blogdown:::insert_image_addin()
blogdown:::insert_image_addin()
# 2. Hechar a andar la pagina
blogdown::serve_site()
# 2. Hechar a andar la pagina
blogdown::serve_site()
# 2. Hechar a andar la pagina
blogdown::serve_site()
?sf::st_intersection
?st_write
?sf::st_write
# 2. Hechar a andar la pagina
blogdown::serve_site()
install.packages("blogdown")
blogdown:::serve_site()
blogdown::install_hugo()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::insert_image_addin()
blogdown:::serve_site()
blogdown:::insert_image_addin()
blogdown:::insert_image_addin()
![](/post/2020-12-04-pivoteando-bases_files/sandwich.png){width=90%}
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::new_post_addin()
blogdown:::preview_site()
blogdown:::insert_image_addin()
blogdown:::preview_site()
blogdown:::insert_image_addin()
blogdown:::serve_site()
